---
title: 'Fitting mixed-effects models'
output:
  html_document:
    self_contained: no
---

```{r}
install.packages("lme4")
install.packages("nlme")
#install.packages("scales")
install.packages("ggplot2")
install.packages("cowplot")
install.packages("dplyr")
```

```{r setup, include=FALSE}
library(dplyr)

# load example data
data <- read.delim("https://www.kuleuven.be/samenwerking/real/real-book/viechtbauer2022_data_esmda_example")

# compute scales of positive and negative affect
data$pa <- rowMeans(data[,c("mood_cheerf", "mood_relaxed", "mood_satisfi")])

data$na <- rowMeans(data[,c("mood_irritat", "mood_anxious", "mood_down", 
                            "mood_guilty", "mood_insecur", "mood_lonely")])

# positive affect
data$pa_b <- ave(data$pa, data$id, FUN=function(x)mean(x, na.rm = TRUE)) # person-mean (between)
data$pa_w <- data$pa - data$pa_b # person-mean centered (within)

# negative affect
data$eventpl_b <- ave(data$eventpl, data$id, FUN=function(x)mean(x, na.rm = TRUE)) # person-mean (between)
data$eventpl_w <- data$eventpl - data$eventpl_b # person-mean centered (within)
```

| Feature / Task                   | **lme4 (lmer)**                          | **nlme (lme)**                                 |
|----------------------------------|------------------------------------------|------------------------------------------------|
| Main function                    | `lmer()`                                 | `lme()`                                        |
| Syntax for random intercepts     | `lmer(y ~ 1 + (1|id), data = df)`        | `lme(y ~ 1, random = ~1|id, data = df)`        |
| Random slopes                    | `lmer(y ~ x + (x|id), data = df)`        | `lme(y ~ x, random = ~x|id, data = df)`        |
| Multiple grouping factors        | Yes (nested/crossed)                     | Limited, mostly nested                         |
| Estimation method                | REML / ML (fast, sparse matrices)        | REML / ML (older implementation)               |
| Handles heteroscedasticity       | Not directly                             | Yes, via `weights = varIdent(...)`             |
| Correlation structures           | Not directly                             | Yes, via `corAR1`, `corCompSymm`, etc.         |
| Extract fixed effects            | `fixef(model)`                           | `fixef(model)`                                 |
| Extract random effects (BLUPs)   | `ranef(model)`                           | `ranef(model)`                                 |
| Fitted values                    | `fitted(model)`                          | `fitted(model)`                                |
| P-values for fixed effects       | Not provided by default (use `lmerTest`) | Provided directly in summary output            |
| Popular extensions               | `lmerTest`, `glmer`, `glmmTMB`           | `gnls`, `gls`                                  |
| Speed / scalability              | Very fast, good for large data           | Slower, better for smaller/moderate data       |


# Null model

```{r, message=FALSE}
# set environment
library(nlme)
library(lme4)
library(ggplot2)
library(cowplot)
library(scales)
```

```{r}
# fit base model
m1 <- lme(pa ~ 1, 
          random = ~1|id,
          data = data, 
          na.action = na.exclude)

summary(m1)
```

```{r}
# fixed effects
fixef(m1)

# random effects
head(ranef(m1))
```

```{r, fig.dim = c(10, 4), warning=F}
# plot individual intercepts and residuals
hist1 <- ggplot(data.frame(value = coef(m1)[[1]]), aes(x = value)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, color = "white") +
  geom_density(linewidth = 0.8, color = "blue") +
  scale_x_continuous(breaks = 1:7) +
  labs(x = "Average Positive Affect", y = "Density") +
  theme_bw()

hist2 <- ggplot(data.frame(value = resid(m1)), aes(x = value)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, color = "white") +
  geom_density(linewidth = 0.8, color = "blue") +
  scale_x_continuous(breaks = 1:7) +
  labs(x = "Residual", y = "Density") +
  theme_bw()
  
plot_grid(hist1, hist2)
```

**Shrinkage**: compare pooled estimates with non-pooled means
```{r, fig.dim = c(10, 4), warning=F}
# compute individual means
indiv_means <- data %>%
  group_by(id) %>%
  summarise(indiv_mean = mean(pa, na.rm = TRUE)) %>%
  ungroup()

# plot pooled vs non-pooled means
hist1 <- ggplot(data.frame(value = coef(m1)[[1]]), aes(x = value)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, color = "white") +
  geom_density(linewidth = 0.8, color = "blue") +
  scale_x_continuous(breaks = 1:7) +
  labs(title = "Average Positive Affect", x = "BLUPs") +
  theme_bw()

hist2 <- ggplot(data.frame(value = indiv_means$indiv_mean), aes(x = value)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, color = "white") +
  geom_density(linewidth = 0.8, color = "blue") +
  scale_x_continuous(breaks = 1:7) +
  labs(title = "Average Positive Affect", x = "Observed means") +
  theme_bw()
  
plot_grid(hist1, hist2)

# pooled vs non-pooled means
head(data.frame(BLUP = coef(m1)[[1]], 
                Obs_Means = indiv_means$indiv_mean))
```

**ICC**: Intraclass Correlation Coefficient
```{r}
int_var <- getVarCov(m1)[1,1] # random intercept variance
res_var <- sigma(m1)^2 # residual variance

int_var / (int_var + res_var)
```

# Adding time as a predictor
```{r, fig.dim = c(10, 8), warning=F}
# plot time variables
d <- data %>% filter(id == "c100") %>% mutate(idx = row_number())

t1 <- ggplot(d, aes(idx, obs)) + geom_line() + geom_point() + 
  labs(x="Index", y="obs") + theme_bw()
t2 <- ggplot(d, aes(idx, day)) + geom_line() + geom_point() + 
  labs(x="Index", y="day") + theme_bw()
t3 <- ggplot(d, aes(idx, beep)) + geom_line() + geom_point() + 
  labs(x="Index", y="beep")     + theme_bw()
t4 <- ggplot(d, aes(idx, beeptime)) + geom_line() + geom_point() + 
  labs(x="Index", y="beeptime") + theme_bw()

plot_grid(t1, t2, t3, t4)
```

**Variance decomposition based on time variables**
```{r, fig.dim = c(5, 4), warning=F, message=F}
# intercept-only model with time-variance components 
m2_lme <- lme(pa ~ 1, 
              random = ~1|id/day/beeptime,
              data = data, 
              na.action = na.omit)

m2_lmer <- lmer(pa ~ 1 + (1|id) + (1|day) + (1 | beeptime) + (1|id:day) +
                  (1|id:beeptime) + (1|day:beeptime),
                data = data)

# model summaries
summary(m2_lme)
summary(m2_lmer)

# extract variance components
vc <- as.data.frame(VarCorr(m2_lmer)) %>%
  group_by(grp) %>%
  summarise(vcov = sum(vcov), .groups = "drop") %>%
  mutate(Prop = vcov / sum(vcov)) %>%
  arrange(Prop)

# clearer plot: sorted horizontal bars with percent labels
ggplot(vc, aes(x = Prop, y = reorder(grp, Prop), fill = grp)) +
  geom_col(width = 0.7, color = "white", show.legend = FALSE) +
  geom_text(aes(label = percent(Prop, accuracy = 0.1)),
            hjust = -0.1, size = 3.2) +
  scale_x_continuous(labels = percent_format(accuracy = 1),
                     expand = expansion(mult = c(0, 0.1))) +
  labs(title = "Variance decomposition for PA",
       x = "Proportion of variance", y = NULL) +
  theme_bw(base_size = 12) 
```

# Adding a L1 predictor

```{r}
# fit model with predictor
m3 <- lme(pa ~ eventpl_w, 
          random = ~eventpl_w|id,
          data = data, 
          na.action = na.omit)

summary(m3)
```

```{r}
# fixed effects
fixef(m3)

# random effects
head(ranef(m3))
```

```{r}
# plot estimates
hist(coef(m3)[[1]], breaks = 30, freq=FALSE, main="", 
     xlab="Intercepts")
hist(coef(m3)[[2]], breaks = 30, freq=FALSE, main="", 
     xlab="Slopes")
hist(resid(m3), breaks = 30, freq=FALSE, main="", 
     xlab="Residuals")
plot(coef(m3)[[1]], coef(m3)[[2]], xlab="Intercept", ylab="Slope")
abline(v=fixef(m3)[1], lty="dotted")
abline(h=fixef(m3)[2], lty="dotted")
```

# Adding covariates

**L2 covariate**
```{r}
# fit model with L2 covariate
m4 <- lme(pa ~ eventpl_w + age, 
          random = ~eventpl|id,
          data = data, 
          na.action = na.omit)

summary(m4)
```

```{r}
# fixed effects
fixef(m4)

# random effects
head(ranef(m4))
```

```{r}
# grand-mean center age
data$age_c <- data$age - mean(aggregate(data, age ~ id, unique)$age)

# fit model with L2 covariate
m4_c <- lme(pa ~ eventpl_w + age_c, 
          random = ~eventpl_w|id,
          data = data, 
          na.action = na.omit)

summary(m4_c)
```

**L1 covariate**
```{r}
# fit model with L1 covariate
m5 <- lme(pa ~ eventpl + use_alcohol, 
          random = ~eventpl + use_alcohol|id,
          data = data, 
          na.action = na.omit)

summary(m5)
```

Card: Fixed vs random effects
There is not yet consensus about how to deal with singularity, or more generally to choose which random-effects specification (from a range of choices of varying complexity) to use. Some proposals include:

 - avoid fitting overly complex models in the first place, i.e. design experiments/restrict models a priori such that the variance-covariance matrices can be estimated precisely enough to avoid singularity (Matuschek et al 2017)

 - use some form of model selection to choose a model that balances predictive accuracy and overfitting/type I error (Bates et al 2015, Matuschek et al 2017)

 - “keep it maximal”, i.e. fit the most complex model consistent with the experimental design, removing only terms required to allow a non-singular fit (Barr et al. 2013), or removing further terms based on p-values or AIC

```{r}
# example RQ: PA <- eventpl within-participants
# covariates: use_alcohol, use_coffee

# base model
m6 <- lme(pa ~ eventpl_b + use_alcohol + use_coffee, 
          random = ~1|id,
          data = data, 
          na.action = na.omit)

# random effect for use_alcohol
m7 <- lme(pa ~ eventpl_b + use_alcohol + use_coffee, 
          random = ~use_alcohol|id,
          data = data, 
          na.action = na.omit)

anova(m6, m7)

# random effect for use_coffee
m8 <- lme(pa ~ eventpl_b + use_alcohol + use_coffee, 
          random = ~use_coffee|id,
          data = data, 
          na.action = na.omit)

anova(m6, m8)

# final model
m8 <- lme(pa ~ eventpl_w + eventpl_b + use_alcohol + use_coffee, 
          random = ~eventpl_w + use_alcohol|id,
          data = data, 
          na.action = na.omit)

summary(m8)
```

# Moderation analysis

**L1 moderation**
```{r}
m9 <- lme(pa ~ eventpl * location, 
          random = ~eventpl|id,
          data = data, 
          na.action = na.omit)

summary(m9)
```

**L2 moderation**
```{r}
m10 <- lme(pa ~ eventpl * status, 
          random = ~eventpl|id,
          data = data,
          na.action = na.omit)

summary(m10)
```

# Mediation analysis

Terminology:  
`1-1-1` eventpl -> use_alcohol -> PA
`1-2-1` eventpl -> XX -> PA

```{r}

```

# Lagged analyses


# Model diagnostics

```{r}
m3 <- lme(pa ~ eventpl_w, 
          random = ~eventpl_w|id,
          data = data, 
          na.action = na.omit)
```

**L1 residuals**
```{r}
# extract fitted values and residuals
res <- resid(m3, type = "normalized")
pred <- fitted(m3)

plot(density(res), main = "Distribution of Level-1 residuals")
qqnorm(res, main = "Q-Q Plot of Level-1 residuals")
qqline(res)
plot(pred, res, main='Predicted vs. Actual Values')
acf(res, main="ACF of Level-1 residuals")
```

```{r}
m3_ar <- lme(pa ~ eventpl_w, 
             random = ~eventpl_w|id,
             data = data, 
             na.action = na.omit,
             correlation = corAR1(form = ~beep|id/day))
```

**L1 residuals**
```{r}
# extract fitted values and residuals
res <- resid(m3_ar, type = "normalized")
pred <- fitted(m3_ar)

plot(density(res), main = "Distribution of Level-1 residuals")
qqnorm(res, main = "Q-Q Plot of Level-1 residuals")
qqline(res)
plot(pred, res, main='Predicted vs. Actual Values')
acf(res, main="ACF of Level-1 residuals")
```

**L2 residuals**
```{r}
# intercept
res_int <- (ranef(m3_ar)["(Intercept)"])[,1]

plot(density(res_int), main = "Distribution of Level-2 Intercept residuals")
qqnorm(res_int, main = "Q-Q Plot of Level-2 Intercept residuals")
qqline(res_int)

# slope
res_slope <- (ranef(m3)["eventpl_w"])[,1]

plot(density(res_slope), main = "Distribution of Level-2 Negative emotion residuals")
qqnorm(res_slope, main = "Q-Q Plot of Level-2 Negative emotion residuals")
qqline(res_slope)
```


# Standardized / additional outputs

**Cohen's d**
```{r}
# model summary
summary(m3)

# cohens d for eventpl: (2*t)/sqrt(df)
(2 * 23.81798) / sqrt(13710)
```

**Confidence intervals**
```{r}
# confidence intervals
intervals(m3, level = .95)
```

**Explained variance**
```{r}

```

# Example write-up


