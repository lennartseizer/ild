---
layout: page
title: Preprocessing
---

## Ziel der Aufbereitung

Die Guideline von [preprocess.esmtools.com](https://preprocess.esmtools.com) strukturiert das Preprocessing entlang eines reproduzierbaren Workflows: (1) Studiendesign verstehen, (2) Rohdaten verlässlich einlesen, (3) Messfenster validieren, (4) fehlende und problematische Beobachtungen klassifizieren, (5) Skalen und abgeleitete Variablen berechnen, (6) Analysedatensatz für das Zielmodell (z. B. LMM) ableiten. Jeder Schritt sollte skriptbasiert dokumentiert werden, damit Auswertungen nachvollziehbar bleiben.

## Studiendesign und Sampling-Schema erfassen

1. **Sampling-Plan dokumentieren**: Notiere erwartete Prompts pro Tag, Stichprobendauer, erlaubte Antwortfenster und Trigger-Logik (signal-, zeit- oder event-basiert).
2. **Messinstrumente katalogisieren**: Halte Item-IDs, Itemtexte, Skalierungen sowie ggf. Reverse-Coding in einer Data-Dictionary-Tabelle fest.
3. **Metadaten sichern**: Sammle Informationen über App-Versionen, Reminder-Logik und Zeitzonen, um spätere Anomalien einordnen zu können.

```r
sampling_plan <- tibble::tribble(
  ~prompt_id, ~scheduled_local_time, ~window_minutes,
  "morning", "08:00", 45,
  "noon",    "13:00", 60,
  "evening", "20:00", 60
)
```

## Rohdaten importieren und aufbereiten

1. **Import**: Lade Rohdaten aus CSV, JSON oder Datenbanken mit konsistenter Zeichencodierung (`UTF-8`) und setze die erwartete Zeitzone (z. B. `Europe/Berlin`).
2. **Zeitvariablen harmonisieren**: Konvertiere Datum- und Zeitangaben in `POSIXct` und berechne `prompt_date` sowie `prompt_local_time` relativ zum Sampling-Plan.
3. **Primärschlüssel prüfen**: Stelle sicher, dass jede Kombination aus `person_id`, `prompt_id` und geplantem Datum eindeutig ist; doppelte Einträge markieren.
4. **Beobachtungen sortieren**: Innerhalb jeder Person chronologisch ordnen und eine laufende Messnummer (`beep`) vergeben.

```r
library(dplyr)
library(lubridate)

ema_long <- ema_raw %>%
  mutate(
    timestamp = ymd_hms(response_time, tz = "Europe/Berlin"),
    prompt_date = as_date(timestamp),
    prompt_local_time = format(with_tz(timestamp, tzone = "Europe/Berlin"), "%H:%M"),
    beep = ave(timestamp, person_id, FUN = seq_along)
  ) %>%
  arrange(person_id, timestamp)
```

## Messfenster und Compliance validieren

1. **Geplante vs. tatsächliche Zeiten matchen**: Verbinde die geplanten Prompts aus dem Sampling-Plan mit den tatsächlichen Antworten, um Antwortlatenzen zu berechnen.
2. **Antwortfenster prüfen**: Flagge Antworten ausserhalb des zulässigen Fensters (`window_minutes`).
3. **Technische Events berücksichtigen**: Ergänze Reminder- oder Error-Logs, um technische Fehlversuche zu unterscheiden.
4. **Compliance-Kennzahlen berechnen**: Anzahl erwarteter Prompts, beantwortete Prompts, Anteil rechtzeitiger Antworten.

```r
ema_compliance <- ema_long %>%
  left_join(sampling_plan, by = "prompt_id") %>%
  mutate(
    scheduled_ts = force_tz(ymd_hm(paste(prompt_date, scheduled_local_time)), tzone = "Europe/Berlin"),
    latency_minutes = as.numeric(difftime(timestamp, scheduled_ts, units = "mins")),
    within_window = abs(latency_minutes) <= window_minutes
  )

compliance_summary <- ema_compliance %>%
  summarise(
    prompts_expected = n(),
    prompts_answered = sum(!is.na(response_value)),
    on_time_rate = mean(within_window, na.rm = TRUE)
  )
```

## Fehlende und problematische Werte klassifizieren

1. **Response-Status codieren**: Verwende Kategorien wie `answered`, `skipped`, `technical_error`, `too_late`.
2. **Itembezogene Ausfällle prüfen**: Erstelle Missingness-Muster pro Item und vergleiche Tageszeiten, um systematische Ausfälle aufzudecken.
3. **Outlier behandeln**: Identifiziere Werte ausserhalb plausibler Skalenbereiche; entscheide über Winsorizing, Trunkierung oder erneute Datenerhebung.
4. **Zwischenspeichern**: Speichere eine Version mit kommentierten Ausschlüssen, um Entscheidungen nachvollziehbar zu halten.

```r
ema_flagged <- ema_compliance %>%
  mutate(
    response_status = dplyr::case_when(
      is.na(response_value) & within_window ~ "missing", 
      is.na(response_value) & !within_window ~ "missed_window",
      !is.na(response_value) & !within_window ~ "late",
      TRUE ~ "answered"
    )
  )

item_missing <- ema_flagged %>%
  tidyr::pivot_longer(starts_with("item_"), names_to = "item", values_to = "value") %>%
  group_by(item, prompt_id) %>%
  summarise(missing_rate = mean(is.na(value)), .groups = "drop")
```

## Skalen, Scores und Zeitvariablen ableiten

1. **Reverse-Coding anwenden**: Nutze Data-Dictionary-Information, um Items mit invertierter Polarität korrekt umzucodieren.
2. **Skalenwerte berechnen**: Mittlere oder summierte Scores pro Messung erstellen und Mindestanzahl beantworteter Items sicherstellen (z. B. ≥ 70 %).
3. **Zeitbezogene Features**: Ergänze Variablen wie `day_in_study`, `time_since_wake`, Wochenend-Indikator oder Feiertage.
4. **Lag- und Lead-Variablen**: Für dynamische Analysen `lag()` bzw. `lead()` pro Person berechnen und fehlende Werte kennzeichnen.

```r
scored_ema <- ema_flagged %>%
  mutate(
    stress_rev = 8 - item_stress_3,  # Beispiel für invertierte Likert-Skala 1-7
    affect_mean = rowMeans(select(., starts_with("item_affect")), na.rm = TRUE),
    day_in_study = as.integer(difftime(timestamp, min(timestamp), units = "days")) + 1,
    weekend = lubridate::wday(timestamp, label = TRUE) %in% c("Sat", "Sun"),
    affect_lag1 = dplyr::lag(affect_mean)
  )
```

## Personenbezogene Kennzahlen und Zentrierung

1. **Between-Level Variablen**: Aggregiere Mittelwerte, Varianzen und Compliance pro Person (`summarise`).
2. **Within-Level Zentrierung**: Führe Group-Mean-Centering für zeitvariable Prädiktoren durch.
3. **Grand-Mean-Centering**: Skaliere zwischenpersonale Merkmale (z. B. Trait-Scores) auf Gesamtmittel.
4. **Zusammenführung**: Verbinde person-level Tabellen (Traits, Demografie) mit dem EMA-Längsschnittdatensatz.

```r
person_level <- scored_ema %>%
  group_by(person_id) %>%
  summarise(
    affect_mean_person = mean(affect_mean, na.rm = TRUE),
    stress_mean_person = mean(item_stress_1, na.rm = TRUE),
    compliance_rate = mean(response_status == "answered"),
    .groups = "drop"
  )

ema_lmm <- scored_ema %>%
  left_join(person_level, by = "person_id") %>%
  group_by(person_id) %>%
  mutate(
    affect_w = affect_mean - affect_mean_person,
    stress_w = item_stress_1 - stress_mean_person
  ) %>%
  ungroup() %>%
  mutate(across(ends_with("_person"), ~ .x - mean(.x, na.rm = TRUE), .names = "{.col}_g"))
```

## Export, Dokumentation und Reproduzierbarkeit

1. **Versionierung**: Speichere den finalen Datensatz (`ema_lmm`) und den aufbereiteten Workflow (z. B. R Markdown, Quarto, Pipeline) unter Versionskontrolle.
2. **Codebook**: Dokumentiere Variablen, Transformationen und Ausschlusskriterien; verweise auf den Sampling-Plan.
3. **Qualitätssicherung**: Automatisiere Checks (z. B. `testthat`, `validate`), die zentrale Kennzahlen und Datenintegrität bei späteren Updates prüfen.
4. **Exportformate**: Stelle Analyse-Teams Dateien in `.rds` oder `.csv` bereit und sichere Rohdaten unverändert.

Mit diesem Guideline-orientierten Workflow entstehen nachvollziehbare, qualitätsgesicherte EMA-Datensätze, die sich unmittelbar für LMM und verwandte zeitabhängige Modelle nutzen lassen.

