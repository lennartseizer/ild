---
title: 'Fitting mixed-effects models'
---

```{r,include=F}
install.packages("lme4")
install.packages("nlme")
install.packages("scales")
install.packages("ggplot2")
install.packages("cowplot")
install.packages("dplyr")
install.packages("r2mlm")
install.packages("parameters")
```

```{r setup, include=FALSE}
library(dplyr)

# load example data
data <- read.delim("https://www.kuleuven.be/samenwerking/real/real-book/viechtbauer2022_data_esmda_example")

# compute scales of positive and negative affect
data$pa <- rowMeans(data[,c("mood_cheerf", "mood_relaxed", "mood_satisfi")])

data$na <- rowMeans(data[,c("mood_irritat", "mood_anxious", "mood_down", 
                            "mood_guilty", "mood_insecur", "mood_lonely")])


data$eventpl_b <- ave(data$eventpl, data$id, FUN=function(x)mean(x, na.rm = TRUE)) 
data$eventpl_w <- data$eventpl - data$eventpl_b 
eventpl_gm <- mean(data$eventpl_b)#mean(aggregate(data, eventpl_b ~ id, unique)$eventpl_b)
data$eventpl_bc <- data$eventpl_b - eventpl_gm

# create lagged variables
data <- data %>%
  arrange(id, obs) %>%                
  group_by(id) %>%     
  # lag by 1 obs
  mutate(eventpl_w_l1 = lag(eventpl_w, n = 1)) %>% 
  # reset each day
  mutate(eventpl_w_l1 = if_else(beep == 1, NA, eventpl_w_l1)) %>%
  ungroup()
```

| Feature / Task                   | **lme4 (lmer)**                          | **nlme (lme)**                                 |
|----------------------------------|------------------------------------------|------------------------------------------------|
| Main function                    | `lmer()`                                 | `lme()`                                        |
| Syntax for random intercepts     | `lmer(y ~ 1 + (1|id), data = df)`        | `lme(y ~ 1, random = ~1|id, data = df)`        |
| Random slopes                    | `lmer(y ~ x + (x|id), data = df)`        | `lme(y ~ x, random = ~x|id, data = df)`        |
| Multiple grouping factors        | Yes (nested/crossed)                     | Limited, mostly nested                         |
| Estimation method                | REML / ML (fast, sparse matrices)        | REML / ML (older implementation)               |
| Handles heteroscedasticity       | Not directly                             | Yes, via `weights = varIdent(...)`             |
| Correlation structures           | Not directly                             | Yes, via `corAR1`, `corCompSymm`, etc.         |
| Extract fixed effects            | `fixef(model)`                           | `fixef(model)`                                 |
| Extract random effects (BLUPs)   | `ranef(model)`                           | `ranef(model)`                                 |
| Fitted values                    | `fitted(model)`                          | `fitted(model)`                                |
| P-values for fixed effects       | Not provided by default (use `lmerTest`) | Provided directly in summary output            |
| Speed / scalability              | Very fast, good for large data           | Slower, better for smaller/moderate data       |


# Null model

```{r, message=FALSE}
# set environment
library(nlme)
library(lme4)
library(ggplot2)
library(cowplot)
library(scales)
library(r2mlm)
library(tidyr)
```

```{r}
# fit base model
m1 <- lme(pa ~ 1, 
          random = ~1|id,
          data = data, 
          na.action = na.omit)

summary(m1)
```

```{r}
# fixed effects
fixef(m1)

# random effects
head(ranef(m1))
```

```{r, fig.dim = c(10, 4), warning=F}
# plot individual intercepts and residuals
hist1 <- ggplot(data.frame(value = coef(m1)[[1]]), aes(x = value)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, color = "white") +
  geom_density(linewidth = 0.8, color = "blue") +
  scale_x_continuous(breaks = 1:7) +
  labs(x = "Average Positive Affect", y = "Density") +
  theme_bw()

hist2 <- ggplot(data.frame(value = resid(m1)), aes(x = value)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, color = "white") +
  geom_density(linewidth = 0.8, color = "blue") +
  scale_x_continuous(breaks = 1:7) +
  labs(x = "Residual", y = "Density") +
  theme_bw()
  
plot_grid(hist1, hist2)
```

**Shrinkage**: compare pooled estimates with non-pooled means
```{r, fig.dim = c(10, 4), warning=F}
# compute individual means
indiv_means <- data %>%
  group_by(id) %>%
  summarise(indiv_mean = mean(pa, na.rm = TRUE)) %>%
  ungroup()

# plot pooled vs non-pooled means
hist1 <- ggplot(data.frame(value = coef(m1)[[1]]), aes(x = value)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, color = "white") +
  geom_density(linewidth = 0.8, color = "blue") +
  scale_x_continuous(breaks = 1:7) +
  labs(title = "Average Positive Affect", x = "BLUPs") +
  theme_bw()

hist2 <- ggplot(data.frame(value = indiv_means$indiv_mean), aes(x = value)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, color = "white") +
  geom_density(linewidth = 0.8, color = "blue") +
  scale_x_continuous(breaks = 1:7) +
  labs(title = "Average Positive Affect", x = "Observed means") +
  theme_bw()
  
plot_grid(hist1, hist2)

# pooled vs non-pooled means
head(data.frame(BLUP = coef(m1)[[1]], 
                Obs_Means = indiv_means$indiv_mean))
```

**ICC**: Intraclass Correlation Coefficient
```{r}
int_var <- getVarCov(m1)[1,1] # random intercept variance
res_var <- sigma(m1)^2 # residual variance

int_var / (int_var + res_var)
```

# Adding time as a predictor
```{r, fig.dim = c(10, 8), warning=F}
# plot time variables
d <- data %>% filter(id == "c100") %>% mutate(idx = row_number())

t1 <- ggplot(d, aes(idx, obs)) + geom_line() + geom_point() + 
  labs(x="Index", y="obs") + theme_bw()
t2 <- ggplot(d, aes(idx, day)) + geom_line() + geom_point() + 
  labs(x="Index", y="day") + theme_bw()
t3 <- ggplot(d, aes(idx, beep)) + geom_line() + geom_point() + 
  labs(x="Index", y="beep")     + theme_bw()
t4 <- ggplot(d, aes(idx, beeptime)) + geom_line() + geom_point() + 
  labs(x="Index", y="resptime") + theme_bw()

plot_grid(t1, t2, t3, t4)
```

**Variance decomposition based on time variables**
```{r, fig.dim = c(5, 4), warning=F, message=F}
# intercept-only model with time-variance components 
m2_lme <- lme(pa ~ 1, 
              random = ~1|id/day/beep,
              data = data, 
              na.action = na.omit)

m2_lmer <- lmer(pa ~ 1 + (1|id) + (1|day) + (1 | beep) + (1|id:day) +
                  (1|id:beep) + (1|day:beep),
                data = data)

# model summaries
summary(m2_lme)
summary(m2_lmer)

# extract variance components
vc <- as.data.frame(VarCorr(m2_lmer)) %>%
  group_by(grp) %>%
  summarise(vcov = sum(vcov), .groups = "drop") %>%
  mutate(Prop = vcov / sum(vcov)) %>%
  arrange(Prop)

# clearer plot: sorted horizontal bars with percent labels
ggplot(vc, aes(x = Prop, y = reorder(grp, Prop), fill = grp)) +
  geom_col(width = 0.7, color = "white", show.legend = FALSE) +
  geom_text(aes(label = percent(Prop, accuracy = 0.1)),
            hjust = -0.1, size = 3.2) +
  scale_x_continuous(labels = percent_format(accuracy = 1),
                     expand = expansion(mult = c(0, 0.1))) +
  labs(title = "Variance decomposition for PA",
       x = "Proportion of variance", y = NULL) +
  theme_bw(base_size = 12) 
```

# Adding a L1 predictor

```{r}
# fit model with predictor
m3 <- lme(pa ~ eventpl_w, 
          random = ~eventpl_w|id,
          data = data, 
          na.action = na.omit)

summary(m3)
```

```{r}
# fixed effects
fixef(m3)

# random effects
head(ranef(m3))
```

```{r}
# plot estimates
hist(coef(m3)[[1]], breaks = 30, freq=FALSE, main="", 
     xlab="Intercepts")
hist(coef(m3)[[2]], breaks = 30, freq=FALSE, main="", 
     xlab="Slopes")
hist(resid(m3), breaks = 30, freq=FALSE, main="", 
     xlab="Residuals")
plot(coef(m3)[[1]], coef(m3)[[2]], xlab="Intercept", ylab="Slope")
abline(v=fixef(m3)[1], lty="dotted")
abline(h=fixef(m3)[2], lty="dotted")
```

# Adding covariates

**L2 covariate**
```{r}
# fit model with L2 covariate
m4 <- lme(pa ~ eventpl_w + eventpl_bc + age, 
          random = ~eventpl_w|id,
          data = data, 
          na.action = na.omit)

summary(m4)
```

```{r}
# fixed effects
fixef(m4)

# random effects
head(ranef(m4))
```

```{r}
# grand-mean center age
data$age_c <- data$age - mean(aggregate(data, age ~ id, unique)$age)

# fit model with L2 covariate
m4_c <- lme(pa ~ eventpl_w + eventpl_bc + age_c, 
          random = ~eventpl_w|id,
          data = data, 
          na.action = na.omit)

summary(m4_c)
```

**Explained variance**
```{r, results="hide", message=FALSE, warning=FALSE}
# decomposition
r2mlm_manual(
  data = data %>% select(all_of(all.vars(formula(m4)))) %>% drop_na(), 
  within_covs  = c("eventpl_w"),
  between_covs = c("eventpl_bc","age"),
  random_covs  = c("eventpl_w"),
  gamma_w      = unname(fixef(m4)["eventpl_w"]),
  gamma_b      = unname(fixef(m4)[c("(Intercept)","eventpl_bc","age")]),
  Tau          = as.matrix(getVarCov(m4)),
  sigma2       = sigma(m4)^2
)
```

```{r}
# Nakagawa's R2
install.packages("performance")
library(performance)
performance::r2(m4)
```

**L1 covariate**
```{r}
# fit model with L1 covariate
m5 <- lme(pa ~ eventpl + use_alcohol, 
          random = ~eventpl + use_alcohol|id,
          data = data, 
          na.action = na.omit)

summary(m5)
```

Card: Fixed vs random effects
There is not yet consensus about how to deal with singularity, or more generally to choose which random-effects specification (from a range of choices of varying complexity) to use. Some proposals include:

 - avoid fitting overly complex models in the first place, i.e. design experiments/restrict models a priori such that the variance-covariance matrices can be estimated precisely enough to avoid singularity (Matuschek et al 2017)

 - use some form of model selection to choose a model that balances predictive accuracy and overfitting/type I error (Bates et al 2015, Matuschek et al 2017)

 - “keep it maximal”, i.e. fit the most complex model consistent with the experimental design, removing only terms required to allow a non-singular fit (Barr et al. 2013), or removing further terms based on p-values or AIC

```{r}
# example RQ: PA <- eventpl within-participants
# covariates: use_alcohol, use_coffee

# base model
m6 <- lme(pa ~ eventpl_bc + use_alcohol + use_coffee, 
          random = ~1|id,
          data = data, 
          na.action = na.omit)

# random effect for use_alcohol
m7 <- lme(pa ~ eventpl_bc + use_alcohol + use_coffee, 
          random = ~use_alcohol|id,
          data = data, 
          na.action = na.omit)

anova(m6, m7)

# random effect for use_coffee
m8 <- lme(pa ~ eventpl_bc + use_alcohol + use_coffee, 
          random = ~use_coffee|id,
          data = data, 
          na.action = na.omit)

anova(m6, m8)

# final model
m8 <- lme(pa ~ eventpl_w + eventpl_bc + use_alcohol + use_coffee, 
          random = ~eventpl_w + use_alcohol|id,
          data = data, 
          na.action = na.omit)

summary(m8)
```

# Moderation analysis

**L1 moderation**
```{r}
m9 <- lme(pa ~ eventpl * soc_alone, 
          random = ~eventpl|id,
          data = data, 
          na.action = na.omit)

summary(m9)
```

**L2 moderation**
```{r}
m10 <- lme(pa ~ eventpl * status, 
          random = ~eventpl|id,
          data = data,
          na.action = na.omit)

summary(m10)
```

# Mediation analysis

Terminology:  
`1-1-1` eventpl -> use_alcohol -> PA
`1-2-1` eventpl -> XX -> PA

```{r}

```

# Lagged analysis

```{r}
# create lagged pa 
data <- data %>%
  arrange(id, obs) %>%                
  group_by(id) %>%     
  mutate(pa_l1 = lag(pa, n = 1)) %>% 
  mutate(pa_l1 = if_else(beep == 1, NA, pa_l1)) %>%
  ungroup()

# fit model with lagged eventpl
m9 <- lme(pa ~ eventpl_w_l1 + pa_l1, 
          random = ~eventpl_w_l1 + pa_l1|id,
          data = data, 
          na.action = na.omit)

summary(m9)
```

# VAR model

**Prepare variables**
```{r}
# pa
data$pa_b <- ave(data$pa, data$id, FUN=function(x)mean(x, na.rm = TRUE)) 
data$pa_w <- data$pa - data$pa_b 
data <- data %>%
  arrange(id, obs) %>%                
  group_by(id) %>%     
  mutate(pa_w_l1 = lag(pa_w, n = 1)) %>% 
  mutate(pa_w_l1 = if_else(beep == 1, NA, pa_w_l1)) %>%
  ungroup()

# na
data$na_b <- ave(data$na, data$id, FUN=function(x)mean(x, na.rm = TRUE)) 
data$na_w <- data$na - data$na_b 
data <- data %>%
  arrange(id, obs) %>%                
  group_by(id) %>%     
  mutate(na_w_l1 = lag(na_w, n = 1)) %>% 
  mutate(na_w_l1 = if_else(beep == 1, NA, na_w_l1)) %>%
  ungroup()
```

**VAR part 1**
```{r}
# b11, b21, sigma11
var1 <- lme(pa ~ pa_w_l1 + na_w_l1,
            random = ~pa_w_l1 + na_w_l1|id,
            data = data,
            na.action = na.exclude)

summary(var1)
```

**VAR part 2**
```{r}
# b21, b22, sigma22
var2 <- lme(na ~ pa_w_l1 + na_w_l1,
            random = ~pa_w_l1 + na_w_l1|id,
            data = data,
            na.action = na.exclude)

summary(var2)
```

**VAR part 3**
```{r}
# sigma 12
cov(residuals(var1), residuals(var2), use = "complete.obs")
```

# Model diagnostics

**Fit model**
```{r}
m3 <- lme(pa ~ eventpl_w, 
          random = ~eventpl_w|id,
          data = data, 
          na.action = na.omit)
```

**L1 residuals**
```{r, message=F}
# prepare residuals/predictions
res  <- residuals(m3, type = "normalized")
pred <- fitted(m3)
df   <- data.frame(res = as.numeric(res), pred = as.numeric(pred))

# density of residuals
p_dens <- ggplot(df, aes(x = res)) + geom_density() +
  labs(title = "Distribution of Level-1 residuals", x = "Residual", y = "Density") +
  theme_bw()

# q-q plot
p_qq <- ggplot(df, aes(sample = res)) + stat_qq() + stat_qq_line() +
  labs(title = "Q-Q Plot of Level-1 residuals", x = "Theoretical quantiles", y = "Sample quantiles") +
  theme_bw()

# predicted vs residuals
p_scatter <- ggplot(df, aes(x = pred, y = res)) + geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = FALSE, linewidth = 0.6) +
  labs(title = "Predicted vs Residuals", x = "Predicted", y = "Residuals") +
  theme_bw()

# ACF of residuals 
acf_obj <- acf(df$res, plot = FALSE, na.action = na.pass)
n_used <- acf_obj$n.used
ci <- qnorm(0.975) / sqrt(n_used)

acf_df <- data.frame(
  lag = as.numeric(acf_obj$lag) * n_used,
  acf = as.numeric(acf_obj$acf)
) %>% filter(lag > 0)

p_acf <- ggplot(acf_df, aes(x = lag, y = acf)) +
  geom_hline(yintercept = 0, linetype = "solid") +
  geom_hline(yintercept = c(-ci, ci), linetype = "dashed") +
  geom_segment(aes(xend = lag, y = 0, yend = acf)) +
  labs(title = "ACF of Level-1 residuals", x = "Lag", y = "ACF") +
  theme_bw() + ylim(c(-.1,.25))

plot_grid(p_dens, p_qq, p_scatter, p_acf)
```

**Fit model with AR errors**
```{r, message=F}
m3_ar <- lme(pa ~ eventpl_w, 
             random = ~eventpl_w|id,
             data = data, 
             na.action = na.omit,
             correlation = corAR1(form = ~beep|id/day))
```

**L1 residuals**
```{r, message = F}
# prepare residuals/predictions
res  <- residuals(m3_ar, type = "normalized")
pred <- fitted(m3_ar)
df   <- data.frame(res = as.numeric(res), pred = as.numeric(pred))

# density of residuals
p_dens <- ggplot(df, aes(x = res)) + geom_density() +
  labs(title = "Distribution of Level-1 residuals", x = "Residual", 
       y = "Density") + theme_bw()

# q-q plot
p_qq <- ggplot(df, aes(sample = res)) + stat_qq() + stat_qq_line() +
  labs(title = "Q-Q Plot of Level-1 residuals", x = "Theoretical quantiles", 
       y = "Sample quantiles") + theme_bw()

# predicted vs residuals
p_scatter <- ggplot(df, aes(x = pred, y = res)) + geom_point(alpha = 0.4) +
  geom_smooth(method = "loess", se = FALSE, linewidth = 0.6) +
  labs(title = "Predicted vs Residuals", x = "Predicted", y = "Residuals") +
  theme_bw()

# ACF of residuals 
acf_obj <- acf(df$res, plot = FALSE, na.action = na.pass)
n_used <- acf_obj$n.used
ci <- qnorm(0.975) / sqrt(n_used)

acf_df <- data.frame(
  lag = as.numeric(acf_obj$lag) * n_used,
  acf = as.numeric(acf_obj$acf)
) %>% filter(lag > 0)

p_acf <- ggplot(acf_df, aes(x = lag, y = acf)) +
  geom_hline(yintercept = 0, linetype = "solid") +
  geom_hline(yintercept = c(-ci, ci), linetype = "dashed") +
  geom_segment(aes(xend = lag, y = 0, yend = acf)) +
  labs(title = "ACF of Level-1 residuals", x = "Lag", y = "ACF") +
  theme_bw() + ylim(c(-.1,.25))

# plot
plot_grid(p_dens, p_qq, p_scatter, p_acf)
```

**L2 residuals**
```{r}
# extract random effects 
re_int <- as.numeric(ranef(m3_ar)[,"(Intercept)"]) # level-2 intercepts
re_slope <- as.numeric(ranef(m3_ar)[,"eventpl_w"]) # level-2 slopes 

df_int <- data.frame(effect = re_int)
df_slope <- data.frame(effect = re_slope)

# intercept residuals
p_int_dens <- ggplot(df_int, aes(x = effect)) + geom_density() +
  labs(title = "Distribution of intercept residuals", x = "Intercept BLUP", 
       y = "Density") + theme_bw()

p_int_qq <- ggplot(df_int, aes(sample = effect)) + stat_qq() + stat_qq_line() +
  labs(title = "Q–Q Plot of intercept residuals", x = "Theoretical quantiles", 
       y = "Sample quantiles") + theme_bw()

# slope residuals
p_slope_dens <- ggplot(df_slope, aes(x = effect)) + geom_density() +
  labs(title = "Distribution of slope residuals", x = "eventpl_w slope BLUP", 
       y = "Density") + theme_bw()

p_slope_qq <- ggplot(df_slope, aes(sample = effect)) + stat_qq() + stat_qq_line() +
  labs(title = "Q–Q Plot of slope residuals", x = "Theoretical quantiles", 
       y = "Sample quantiles") + theme_bw()

# plot
plot_grid(p_int_dens, p_int_qq, p_slope_dens, p_slope_qq)
```

# Standardized / additional outputs

**Confidence intervals**
```{r}
# confidence intervals
intervals(m3, level = .95)
```

**Explained variance**
```{r}


```

**Standardized coefficients**
```{r}
library(parameters)
standardize_parameters(m3)
```

**Cohen's d**

Framework: https://doi.org/10.1037/a0014699, https://doi.org/10.1037/a0030048  
Detailed tutorial: https://solomonkurz.netlify.app/blog/2021-04-22-effect-sizes-for-experimental-trials-analyzed-with-multilevel-growth-models-two-of-two/

d_GMA = b_int * time / SD_pooled

SD_pooled = sqrt((var_c_pre + var_p_pre)/2)

```{r}
# fit model
m10 <- lme(pa ~ day * status, 
           random = ~day|id,
           data = data[!data$status == "depressed",], 
           na.action = na.omit)

summary(m10)

# psychotic sd_d1
sd_d1_p <- sd(data$pa[data$status=="psychotic" & data$day==1], na.rm = T)

# control sd_d1
sd_d1_c <- sd(data$pa[data$status=="control" & data$day==1], na.rm = T)

# pooled sd
pooled_sd <- sqrt((sd_d1_p^2 + sd_d1_c^2) / 2)

# d_gma
as.numeric(fixef(m10)["day:statuspsychotic"]) *5 / pooled_sd
```

# Example write-up


# Exercises
1. (a) Estimate a model that predicts negative affect based on whether participants are alone or with others. (b) Test whether the previous effect is moderated by how pleasant the company of others is experienced.

2. (a) Estimate the time trend of negative affect over the study period, and (b) whether this time trend differs between mental health status groups.
